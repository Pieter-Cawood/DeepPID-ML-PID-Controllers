Metadata-Version: 2.4
Name: deeppid
Version: 0.1.0
Summary: Experiments with PID and ML-based adaptive PID controllers
Author: Pieter Cawood, Contributors
License: MIT
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: numpy>=1.24
Requires-Dist: scipy>=1.10
Requires-Dist: matplotlib>=3.7
Requires-Dist: torch>=2.2
Dynamic: license-file

# DeepPID ‚Äî A Deep Learning‚ÄìBased Adaptive PID Controller

[![CI](https://github.com/Pieter-Cawood/DeepPID/actions/workflows/ci.yml/badge.svg)](https://github.com/Pieter-Cawood/DeepPID/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](./LICENSE)

<div style="display: flex; align-items: flex-start;">
  <div style="flex: 1;">

A **professional, documented playground** for experimenting with **PID** and **machine-learning-based controllers**.  
DeepPID provides both **traditional** and **neural adaptive controllers** in a single, consistent framework, complete with a live **Tkinter + Matplotlib GUI** for interactive benchmarking.

Through extensive simulation and real-time tests on **nonlinear**, **coupled**, and **time-varying plants**, it is demonstrated that the **ML-based adaptive models** (*GRU*, *MLP*, and *Transformer* variants) consistently **outperform conventional PID and Cascade-PID controllers** in both transient and steady-state performance.

The adaptive models achieve:
- ‚ö° **Faster convergence** with minimal overshoot  
- üéØ **Near-zero steady-state error** across diverse process conditions  
- üß© **Robustness** to parameter drift and actuator limits without manual re-tuning  

These results confirm that **data-driven adaptation‚Äîwhen combined with physical constraints‚Äîgeneralizes PID control** beyond fixed-gain heuristics while maintaining interpretability and stability.

  </div>
  <div style="margin-left: 20px; flex-shrink: 0;">
    <img src="docs/deeppid.png" alt="DeepPID Architecture" width="340"><br>
    <em>DeepPID ‚Äî Hybrid classical & ML-based control framework.</em>
  </div>
</div>

---

### GRUController ‚Äî Adaptive Neural Controller (PID-inspired)

A gated recurrent unit (GRU) network that directly predicts actuator speeds based on recent state history.  
It embeds **PID-like control objectives**‚Äîcomposition matching, total flow regulation, smoothness, and bounded actuation‚Äîinto its online loss function.  
While not using explicit PID equations, it behaves as a **hybrid adaptive controller**, combining physical constraints with data-driven prediction.  
This approach consistently **outperforms fixed-gain PID** under nonlinear, coupled, or drifting plant conditions, achieving **near-zero steady-state error** and **smoother transients**.

---

The GUI (`examples/test.py`) lets you:
- Choose different **plant problems** (tank, flow, quadcopter-like, etc.)
- Switch between **controllers** (PID, CascadePID, MLP, GRU, Transformer, etc.)
- Observe **real-time set-point tracking**, **mean absolute error (MAE)** curves, and **controller outputs**
- See which approach adapts fastest to nonlinear or coupled dynamics

<p align="center">
  <img src="docs/gui.png" alt="DeepPID GUI"><br>
  <em>Interactive GUI ‚Äî live comparison of controller performance.</em>
</p>

---

## What‚Äôs inside

- **PID**: IMC‚Äëstyle auto‚Äëtuned PID with anti‚Äëwindup, bumpless transfer, and online refinement.  
- **CascadePID**: stabilized inner PID with outer composition/total loops.  
- **Neural controllers**: MLP, GRU, Transformer, PINN‚Äëflavored, hybrid MPC stub, and safety‚Äëwrapped RL stub.  
- **GUI**: real‚Äëtime MAE table + history plot for apples‚Äëto‚Äëapples comparisons.  
- **Packaging**: imports work (`import deeppid`) and examples run out of the box.

## Install (editable)

```bash
python -m venv .venv
# Linux/macOS
source .venv/bin/activate
# OR Windows PowerShell
.venv\Scripts\activate
pip install -e .
```

## Quick start (GUI)

```bash
python examples/test.py
```

This launches the controller shoot‚Äëout app. Choose any plant from the dropdown, pick a driver
(controller), and watch the **real‚Äëtime mix error** and **MAE history** update as the set‚Äëpoint moves.

## Project layout

```text
deeppid/
  controllers/
    controllers.py        # PID, CascadePID, MLP, GRU, Transformer, etc.
  envs/
    problems.py           # ‚ÄúProblems‚Äù/plants with labels, units, limits
examples/
  test.py                 # Tk + Matplotlib live comparison app
tests/                    # (optional) put your pytest tests here
```

## How the GRU controller works (and why it‚Äôs different from PID)

**Conventional PID** computes the next actuation using fixed (or slowly tuned) gains `Kp, Ki, Kd`
around an interpretable structure with anti‚Äëwindup and filters. It‚Äôs great when the plant can be
reasonably approximated by first/second‚Äëorder dynamics and the operating point doesn‚Äôt move too much.

**GRU controller (adaptive & live)** takes a different tack:

- **State** each tick: `[target ratio, total set‚Äëpoint, recent measured flows, previous speeds]`
- **Sequence model**: a GRU processes the recent context to estimate the next speeds in one shot
- **Hard safety layer**: speeds are **slew‚Äëlimited** and **clamped** to `[min, max]`
- **Online objective** (optimized every few steps):
  - match **composition** (fractions) to target
  - match **total** output to the requested value
  - keep **smooth** changes (actuator wellness)
  - stay inside bounds with a **soft barrier**
  - optionally track a reference/baseline (e.g., PID suggestion)
- **Why it helps**: when the plant is nonlinear, coupled, or operating conditions drift, the GRU
  can ‚Äúlearn‚Äù mappings PID would need re‚Äëtuning for. You still keep the same safety rails as PID.

You can inspect all loss terms and constraints in `controllers.py` (classes `GRUController`, `MLPController`).
Everything is implemented to be **stable‚Äëby‚Äëconstruction**: we never bypass slew/clamp and we bias to
baseline allocations when signals are missing or become non‚Äëfinite.

## License

MIT
